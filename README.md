## WaveNet: A Generative Model for Raw Audio

- code for the [paper](http://arxiv.org/abs/1609.03499)
- [この記事](http://musyoku.github.io/2016/09/18/wavenet-a-generative-model-for-raw-audio/)で実装したコードです。

まだ完成していませんが音声の生成はできます。

#### Todo:
- [x] Generating audio
- [ ] Local conditioning
- [ ] Global conditioning

### Requirements

- Chainer 1.21
- scipy.io.wavfile

### Preprocessing

Donwsample your .wav to 16KHz / 8KHz to speed up convergence.

- [Aaudacity](http://www.audacityteam.org/)

### Create data directory

Add all .wav files to `/train_audio/wav`

### Training

`python train.py -w wav --lr 0.001`

We recommend to stop training if the error saturates and lower the learning rate and start training again.

e.g.

0.001 -> 0.0005 -> 0.00025 -> 0.00001

学習率の調整はわりとシビアです。

放置しておく場合は0.00001以下の値に設定します。

### Generating audio

`python generate.py -s 5 --fast`

Passing `--fast` will generate audio faster than original WaveNet.

#### Listen to a sample generated by WaveNet

[🎶 music](https://drive.google.com/file/d/0ByQaxyG1S5JRWUZrQkpaMTJRNFk/view)

## Implementation

![figure](https://github.com/musyoku/musyoku.github.io/blob/master/images/post/2016-09-17/arch.png?raw=true)

![figure](https://github.com/musyoku/musyoku.github.io/blob/master/images/post/2016-09-17/block.png?raw=true)

![figure](https://github.com/musyoku/musyoku.github.io/blob/master/images/post/2016-09-17/actual_data.png?raw=true)

![figure](https://pbs.twimg.com/media/C4xfueRWIAAtrwJ.png)

[https://twitter.com/heiga_zen/status/832145314559750145](https://twitter.com/heiga_zen/status/832145314559750145)