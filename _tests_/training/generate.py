from scipy.io import wavfile
import numpy as np
import os, sys
sys.path.append(os.path.abspath(os.path.join(os.getcwd(), "../../")))
from args import args
from model import params, wavenet
import data

def main():
	# compute required input width
	num_layers = len(params.residual_conv_channels)
	receptive_steps_per_unit = params.residual_conv_filter_width ** num_layers
	receptive_steps = (receptive_steps_per_unit - 1) * params.residual_num_blocks + 1
	input_width = receptive_steps
	# padding for causal conv block
	input_width += len(params.causal_conv_channels)

	# quantized signals generated by WaveNet
	generated_quantized_audio = np.zeros((input_width, ), dtype=np.int32)

	for time_step in xrange(1000):
		# quantized signals in receptive field
		padded_quantized_x_batch = generated_quantized_audio[-input_width:].reshape((1, -1))

		# convert to image
		padded_x_batch = data.onehot_pixel_image(padded_quantized_x_batch, quantization_steps=params.quantization_steps)

		# generate next signal
		softmax = wavenet.forward_one_step(padded_x_batch, apply_softmax=True, as_numpy=True)
		softmax = softmax[0, :, 0, -1]
		generated_quantized_signal = np.random.choice(np.arange(params.quantization_steps), p=softmax)
		generated_quantized_audio = np.append(generated_quantized_audio, [generated_quantized_signal], axis=0)
		print generated_quantized_signal,


if __name__ == '__main__':
	main()
